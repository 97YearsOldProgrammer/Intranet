
import argparse
import math
import time
from pathlib import Path

import torch
import torch.nn as nn

from lib import intranet as it

parser = argparse.ArgumentParser(description="Train the IntraNet CNN+BLSTM model on tokenised genomic data.")
parser.add_argument("corpus", type=str,
    help="Path to the tokenised corpus generated by data2token.py.")
parser.add_argument("labels", type=str,
    help="Path to the label sequence file aligned with the corpus.")
parser.add_argument("embeddings", type=str,
    help="Path to the pre-trained embedding matrix (GloVe format).")
parser.add_argument("--epochs", type=int, default=10,
    help="Number of training epochs [%(default)d].")
parser.add_argument("--batch-size", type=int, default=16,
    help="Mini-batch size [%(default)d].")
parser.add_argument("--lr", type=float, default=1e-3,
    help="Learning rate for Adam optimiser [%(default)g].")
parser.add_argument("--test-split", type=float, default=0.2,
    help="Fraction of data reserved for evaluation [%(default).2f].")
parser.add_argument("--num-workers", type=int, default=0,
    help="Number of worker processes for data loading [%(default)d].")
parser.add_argument("--seed", type=int, default=42,
    help="Random seed for dataset splitting [%(default)d].")
parser.add_argument("--save-path", type=str, default=None,
    help="Optional destination to store the trained model weights.")
args = parser.parse_args()



# Detect Trainning Device
use_amp         = False
autocast_ctx    = None
scaler          = None

if torch.cuda.is_available():
    device = torch.device("cuda")
    print("Using CUDA (NVIDIA GPU)")
    # CUDA autocast + GradScaler
    from torch.cuda.amp import autocast as cuda_autocast, GradScaler
    autocast_ctx = cuda_autocast
    scaler = GradScaler()
    use_amp = True

elif torch.backends.mps.is_available():
    device = torch.device("mps")
    print("Using MPS (Apple Silicon)")
    # MPS autocast (no GradScaler typically needed)
    from torch.amp import autocast as mps_autocast
    autocast_ctx = lambda: mps_autocast('mps')  # context manager with backend string
    scaler = None
    use_amp = True

else:
    device = torch.device("cpu")
    print("Using CPU (FP32)")

# Loading embedding vector
embeddings = it.parse_glove_matrix(args.embeddings)
if not embeddings:
    raise ValueError(f"No embeddings parsed from {args.embeddings}.")

sample_vector = next(iter(embeddings.values()))
embedding_dim = sample_vector.shape[-1]

# Prepare Dataset
dataset = it.SplicingDataset(args.corpus, embeddings, args.labels)

# Creating label and prediction classes
unique_labels   = sorted(set(label for label_seq in dataset.labels for label in label_seq))
num_classes     = len(unique_labels)

if num_classes < 2:
    raise ValueError(
        "At least two classes are required for training. "
        "Verify that the label file encodes multiple feature types."
    )

# Prepare Trainning Set
train_loader, test_loader = it.prepare_dataloaders(
    dataset,
    batch_size=args.batch_size,
    test_split=args.test_split,
    num_workers=args.num_workers,
    seed=args.seed,
)

# Run CNN+BLSTM Model
model = it.IntraNet(embedding_dim=embedding_dim, num_classes=num_classes)
model.to(device)

# Model Stats
total_params        = sum(p.numel() for p in model.parameters())
trainable_params    = sum(p.numel() for p in model.parameters() if p.requires_grad)
print(f"Total parameters: {total_params:,}")
print(f"Trainable parameters: {trainable_params:,}")

# Trainning
loss_fn     = nn.CrossEntropyLoss(ignore_index=-100)    # ignore label padding of -100
optimiser   = torch.optim.Adam(model.parameters(), lr=args.lr)

# Monitor the Learning Rate
scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
    optimiser, mode='min', factor=0.5, patience=3
)

for epoch in range(1, args.epochs + 1):
    model.train()
    running_loss = 0.0
    running_examples = 0
    start_time = time.time()

    for batch_idx, (inputs, targets, lengths) in enumerate(train_loader, start=1):
        inputs  = inputs.to(device)
        targets = targets.to(device)
        lengths = lengths.to(device)
        optimiser.zero_grad(set_to_none=True)

        if use_amp:
            with autocast_ctx():
                logits = model(inputs, lengths)
                loss = loss_fn(logits.permute(0, 2, 1), targets)
            if scaler:
                scaler.scale(loss).backward()
                scaler.step(optimiser)
                scaler.update()
            else:
                loss.backward()
                optimiser.step()
        else:
            logits = model(inputs, lengths)
            loss = loss_fn(logits.permute(0, 2, 1), targets)
            loss.backward()
            optimiser.step()

        # Update metrics
        valid_mask = (targets != -100)
        batch_tokens = valid_mask.sum().item()
        running_loss += loss.item() * batch_tokens
        running_examples += batch_tokens

    train_loss = running_loss / running_examples if running_examples else float("nan")

    # --- Validation ---
    test_loss, test_accuracy = it.evaluate(model, test_loader, device, loss_fn)

    log_message = f"Epoch {epoch:03d}: train_loss={train_loss:.6f}"
    if not math.isnan(test_loss):
        log_message += f", test_loss={test_loss:.6f}, test_acc={test_accuracy:.4f}"
        scheduler.step(test_loss)  # reduce LR on plateau
    print(log_message)

# Save trained model
if args.save_path:
    save_path = Path(args.save_path)
    save_path.parent.mkdir(parents=True, exist_ok=True)
    torch.save(model.state_dict(), save_path)
    print(f"Model checkpoint saved to {save_path}")
